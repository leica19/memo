
# Kubernetesはどんなことができるの?

モダンなWebサービスでは、
ユーザはアプリケーションが24時間365日利用可能であることを期待しており、
開発者はそれらのアプリケーションの新しいバージョンを1日に数回デプロイすることを期待しています。
コンテナ化は、パッケージソフトウェアがこれらの目標を達成するのを助け、
アプリケーションをダウンタイムなしで簡単かつ迅速にリリース、アップデートできるようにします。
Kubernetesを使用すると、コンテナ化されたアプリケーションをいつでもどこでも好きなときに実行できるようになり、
それらが機能するために必要なリソースとツールを見つけやすくなります。
Kubernetesは、コンテナオーケストレーションにおけるGoogleのこれまでの経験と、コミュニティから得られた最善のアイデアを組み合わせて設計された、
プロダクションレディなオープンソースプラットフォームです。

# Kubernetesの基本モジュール

## Kubernetesクラスタ

Kubernetesは、
単一のユニットとして機能するように接続された、可用性の高いコンピュータのクラスタをまとめあげます。
Kubernetesの抽象化により、コンテナ化されたアプリケーションを個々のマシンに特に結び付けることなくクラスタにデプロイできます。
この新しいデプロイモデルを利用するには、
アプリを個々のホストから切り離す方法でアプリをパッケージ化：コンテナ化する必要があります。
コンテナ化されたアプリケーションは、
アプリケーションがホストに深く統合されたパッケージとして
特定のマシンに直接インストールされていた従来のデプロイモデルよりも柔軟で、
より迅速に利用可能です。Kubernetesはより効率的な方法で、クラスタ全体のアプリケーションコンテナの配布とスケジューリングを自動化します。Kubernetesはオープンソースのプラットフォームであり、プロダクションレディです。

Kubernetesクラスタは以下の2種類のリソースで構成されています:

- マスターがクラスタを管理する
- Nodeがアプリを動かすワーカーとなる

Kubernetesは、
コンピュータクラスタ内およびコンピュータクラスタ間でのアプリケーションコンテナの配置
(スケジューリング)および実行を調整する、
プロダクショングレードのオープンソースプラットフォームです。

マスターはクラスタの管理を担当します。
マスターは、アプリのスケジューリング、望ましい状態の維持、アプリのスケーリング、新しい更新のロールアウトなど、
クラスタ内のすべての動作をまとめあげます。

Nodeは、k8sクラスタのワーカーマシンとして機能するVMまたは物理マシンです。
各Nodeにはkubeletがあり、
これはNodeを管理し、k8sマスターと通信するためのエージェントです。
NodeにはDockerやrktなどのコンテナ操作を処理するためのツールもあるはずです。
プロダクションのトラフィックを処理するk8sクラスタには、最低３つのNodeが必要です。

マスターはクラスタを管理するために、
Nodeは実行中のアプリケーションをホストするために使用されます。

Kubernetesにアプリケーションをデプロイするときは、
マスターにアプリケーションコンテナを起動するように指示します。
マスターはコンテナがクラスタのNodeで実行されるようにスケジュールします。
Nodeは、マスターが公開しているKubernetes APIを使用してマスターと通信します。
エンドユーザーは、Kubernetes APIを直接使用して対話することもできます。

Kubernetesクラスタは、物理マシンまたは仮想マシンのどちらにも配置できます。
Kubernetes開発を始めるためにMinikubeを使うことができます。
Minikubeは、ローカルマシン上にVMを作成し、
1つのNodeのみを含む単純なクラスタをデプロイする軽量なKubernetes実装です。
Minikubeは、Linux、macOS、およびWindowsシステムで利用可能です。
Minikube CLIは、起動、停止、ステータス、削除など、
クラスタを操作するための基本的なブートストラップ操作を提供します。
ただし、このチュートリアルでは、
Minikubeがプリインストールされた状態で提供されているオンラインのターミナルを使用します。

# kubectlを使ったDeploymentの作成

## Kubernetes Deployments

実行中のKubernetesクラスタを入手すると、
その上にコンテナ化アプリケーションをデプロイすることができます。
そのためには、KubernetesのDeployment の設定を作成します。

DeploymentはKubernetesにあなたのアプリケーションのインスタンスを作成し、
更新する方法を指示します。
Deploymentを作成すると、
Kubernetesマスターは指定されたアプリケーションインスタンスを
クラスタ内の個々のNodeにスケジュールします。

アプリケーションインスタンスが作成されると、
Kubernetes Deploymentコントローラーは、
それらのインスタンスを継続的に監視します。
インスタンスをホストしているNodeが停止、削除された場合、
Deploymentコントローラーがそれを置き換えます。
これは、マシンの故障やメンテナンスに対処するための
セルフヒーリングの仕組みを提供しています。

オーケストレーションが入る前の世界では、
インストールスクリプトを使用してアプリケーションを起動することはよくありましたが、
マシン障害が発生した場合に復旧する事はできませんでした。

アプリケーションのインスタンスを作成し、
それらをNode間で実行し続けることで、
Kubernetes Deploymentsはアプリケーションの管理に
根本的に異なるアプローチを提供します。

Deploymentsは、
アプリケーションのインスタンスを作成および更新する資格があります。

## Kubenretes上にはじめてのアプリケーションをデプロイする

Kubernetesのコマンドラインインターフェイスであるkubectlを使用して、
Deploymentを作成、管理できます。
kubectlは
Kubernetes APIを使用してクラスタと対話します。
このモジュールでは、
Kubernetesクラスタでアプリケーションを実行する
Deploymentを作成するために必要な、
最も一般的なkubectlコマンドについて学びます。

Deploymentを作成するときは、
アプリケーションのコンテナイメージと
実行するレプリカの数を指定する必要があります。
Deploymentを更新することで、
あとでその情報を変更できます。
チュートリアルのモジュール5と6では、
Deploymentをどのようにスケール、更新できるかについて説明します。

最初のDeploymentには、
DockerコンテナにパッケージされたNode.jsアプリケーションを使用します。
Node.jsアプリケーションを作成してDockerコンテナをデプロイするには、
Hello Minikubeチュートリアルの指示に従ってください。

Kubernetesにデプロイするには、
アプリケーションをサポートされているコンテナ形式のいずれかに
パッケージ化する必要があります。

# PodとNodeについて

## Kubernetes Pod

モジュール2でDeploymentを作成したときに、
KubernetesはアプリケーションインスタンスをホストするためのPod
を作成しました。
Podは、1つ以上のアプリケーションコンテナ(Dockerやrktなど)のグループと
それらのコンテナの共有リソースを表すKubernetesの抽象概念です。 
Podには以下のものが含まれます:

共有ストレージ(ボリューム)
ネットワーキング(クラスタに固有のIPアドレス)
コンテナのイメージバージョンや使用するポートなどの、各コンテナをどう動かすかに関する情報

Podは、
アプリケーション固有の「論理ホスト」をモデル化し、
比較的密接に結合された
さまざまなアプリケーションコンテナを含むことができます。 
たとえば、Podには、Node.jsアプリケーションを含むコンテナと、
Node.js Webサーバによって
公開されるデータを供給する別のコンテナの両方を含めることができます。
Pod内のコンテナはIPアドレスとポートスペースを共有し、
常に同じ場所に配置され、
同じスケジュールに入れられ、
同じNode上の共有コンテキストで実行されます。

Podは、Kubernetesプラットフォームの原子単位です。
Kubernetes上にDeploymentを作成すると、
そのDeploymentはその中にコンテナを持つPodを作成します
(コンテナを直接作成するのではなく)。 
各Podは、スケジュールされているNodeに関連付けられており、
終了(再起動ポリシーに従って)または削除されるまでそこに残ります。 
Nodeに障害が発生した場合、
同じPodがクラスタ内の他の使用可能なNodeにスケジュールされます。

Podは
1つ以上のアプリケーションコンテナ(Dockerやrktなど)のグループであり、
共有ストレージ(ボリューム)、IPアドレス、それらの実行方法に関する情報が
含まれています。

## Node

Podは常にNode上で動作します。
NodeはKubernetesではワーカーマシンであり、
クラスタによって仮想、物理マシンのどちらであってもかまいません。
各Nodeはマスターによって管理されます。
Nodeは複数のPodを持つことができ、
Kubernetesマスターは
クラスタ内のNode間でPodのスケジュールを自動的に処理します。
マスターの自動スケジューリングは
各Nodeで利用可能なリソースを考慮に入れます。

コンテナ同士が密接に結合され、
ディスクなどのリソースを共有する必要がある場合は、
コンテナを１つのPodにまとめてスケジュールする必要があります。

すべてのKubernetesNodeでは少なくとも以下のものが動作します。

Kubelet: 
  KubernetesマスターとNode間の通信を担当するプロセス。
  マシン上で実行されているPodとコンテナを管理します。

レジストリからコンテナイメージを取得し、
コンテナを解凍し、アプリケーションを実行することを担当する、
Docker、rktのようなコンテナランタイム。

# kubectlを使ったトラブルシューティング

チュートリアル
Hello Minikube
Kubernetesの基本を学ぶ
Kubernetesの基本を学ぶ
クラスタの作成
Minikubeを使ったクラスタの作成
対話型チュートリアル - クラスタの作成
アプリケーションのデプロイ
kubectlを使ったDeploymentの作成
対話型チュートリアル - アプリケーションのデプロイ
アプリケーションの探索
PodとNodeについて
対話型チュートリアル - デプロイしたアプリケーションの探索
アプリケーションの公開
Serviceを使ったアプリケーションの公開
対話型チュートリアル - アプリケーションの公開
アプリケーションのスケーリング
アプリケーションの複数インスタンスを実行
対話型チュートリアル - アプリケーションのスケーリング
アプリケーションのアップデート
ローリングアップデートの実行
対話型チュートリアル - アプリケーションのアップデート
Online Training Courses
Overview of Kubernetes Online Training (EN)
Configuration
Configuring Redis using a ConfigMap (EN)
Stateless Applications
Exposing an External IP Address to Access an Application in a Cluster (EN)
Example: Deploying PHP Guestbook application with Redis (EN)
Example: Add logging and metrics to the PHP / Redis Guestbook example (EN)
Stateful Applications
StatefulSet Basics (EN)
Example: Deploying WordPress and MySQL with Persistent Volumes (EN)
Example: Deploying Cassandra with Stateful Sets (EN)
Running ZooKeeper, A Distributed System Coordinator (EN)
Clusters
AppArmor (EN)
Services
Using Source IP (EN)
Edit This Page

PodとNodeについて
目標
KubernetesのPodについて学ぶ
KubernetesのNodeについて学ぶ
デプロイされたアプリケーションのトラブルシューティング
Kubernetes Pod
モジュール2でDeploymentを作成したときに、KubernetesはアプリケーションインスタンスをホストするためのPodを作成しました。Podは、1つ以上のアプリケーションコンテナ(Dockerやrktなど)のグループとそれらのコンテナの共有リソースを表すKubernetesの抽象概念です。 Podには以下のものが含まれます:

共有ストレージ(ボリューム)
ネットワーキング(クラスタに固有のIPアドレス)
コンテナのイメージバージョンや使用するポートなどの、各コンテナをどう動かすかに関する情報
Podは、アプリケーション固有の「論理ホスト」をモデル化し、比較的密接に結合されたさまざまなアプリケーションコンテナを含むことができます。 たとえば、Podには、Node.jsアプリケーションを含むコンテナと、Node.js Webサーバによって公開されるデータを供給する別のコンテナの両方を含めることができます。Pod内のコンテナはIPアドレスとポートスペースを共有し、常に同じ場所に配置され、同じスケジュールに入れられ、同じNode上の共有コンテキストで実行されます。

Podは、Kubernetesプラットフォームの原子単位です。 Kubernetes上にDeploymentを作成すると、そのDeploymentはその中にコンテナを持つPodを作成します(コンテナを直接作成するのではなく)。 各Podは、スケジュールされているNodeに関連付けられており、終了(再起動ポリシーに従って)または削除されるまでそこに残ります。 Nodeに障害が発生した場合、同じPodがクラスタ内の他の使用可能なNodeにスケジュールされます。

まとめ:
Pod
Node
kubectlの主要なコマンド
Podは1つ以上のアプリケーションコンテナ(Dockerやrktなど)のグループであり、共有ストレージ(ボリューム)、IPアドレス、それらの実行方法に関する情報が含まれています。


Podの概要



Node
Podは常にNode上で動作します。NodeはKubernetesではワーカーマシンであり、クラスタによって仮想、物理マシンのどちらであってもかまいません。各Nodeはマスターによって管理されます。Nodeは複数のPodを持つことができ、Kubernetesマスターはクラスタ内のNode間でPodのスケジュールを自動的に処理します。マスターの自動スケジューリングは各Nodeで利用可能なリソースを考慮に入れます。

すべてのKubernetesNodeでは少なくとも以下のものが動作します。

Kubelet: KubernetesマスターとNode間の通信を担当するプロセス。マシン上で実行されているPodとコンテナを管理します。
レジストリからコンテナイメージを取得し、コンテナを解凍し、アプリケーションを実行することを担当する、Docker、rktのようなコンテナランタイム。
コンテナ同士が密接に結合され、ディスクなどのリソースを共有する必要がある場合は、コンテナを1つのPodにまとめてスケジュールする必要があります。


Nodeの概要

kubectlを使ったトラブルシューティング
モジュール2では、
kubectlのコマンドラインインターフェースを使用しました。
モジュール3でもこれを使用して、
デプロイされたアプリケーションとその環境に関する情報を入手します。
最も一般的な操作は、次のkubectlコマンドで実行できます。

kubectl get - リソースの一覧を表示
kubectl describe - 単一リソースに関する詳細情報を表示
kubectl logs - 単一Pod上の単一コンテナ内のログを表示
kubectl exec - 単一Pod上の単一コンテナ内でコマンドを実行

これらのコマンドを使用して、
アプリケーションがいつデプロイされたか、
それらの現在の状況、実行中の場所、
および構成を確認することができます。

クラスタのコンポーネントとコマンドラインの詳細についてわかったので、
次にデプロイしたアプリケーションを探索してみましょう。

NodeはKubernetesではワーカーマシンであり、
クラスタに応じてVMまたは物理マシンになります。 
複数のPodを1つのNodeで実行できます。

# Serviceを使ったアプリケーションの公開

## Kubernetes Serviceの概要

Kubernetes Podの寿命は永続的ではありません。
実際、Podにはライフサイクルがあります。
ワーカーのNodeが停止すると、
そのNodeで実行されているPodも失われます。
そうなると、ReplicationControllerは、
新しいPodを作成してアプリケーションを実行し続けるために、
クラスタを動的に目的の状態に戻すことができます。
別の例として、3つのレプリカを持つ画像処理バックエンドを考えます。
それらのレプリカは交換可能です。
フロントエンドシステムは、バックエンドのレプリカを気にしたり、
Podが失われて再作成されたとしても配慮すべきではありません。
ただし、k8sクラスタ内の各Podは、
同じNode上のPodであっても一意のIPアドレスを持っているため、
アプリケーションが機能し続けるように、
Pod間の変更を自動的に調整する方法が必要です。

KubernetesのServiceは、
Podの論理セットと、それらにアクセスするためのポリシーを
定義する抽象概念です。
Serviceによって、依存Pod間の疎結合が可能になります。
Serviceは、すべてのKubernetesオブジェクトのように、
YAML(推奨)またはJSONを使って定義されます。
Serviceが対象とするPodのセットは通常、
LabelSelectorによって決定されます
(なぜ仕様にセレクタを含めずにServiceが
必要になるのかについては下記を参照してください)。

各Podには固有のIPアドレスがありますが、
それらのIPは、Serviceなしではクラスタの外部に公開されません。
Serviceによって、アプリケーションはトラフィックを
受信できるようになります。
ServiceSpecでtypeを指定することで、
Serviceをさまざまな方法で公開することができます。

ClusterIP (既定値) 
  - クラスタ内の内部IPでServiceを公開します。
    この型では、Serviceはクラスタ内からのみ到達可能になります。

NodePort 
  - NATを使用して、
    クラスタ内の選択された各Nodeの同じポートにServiceを公開します。
    <NodeIP>:<NodePort>を使用して
    クラスタの外部からServiceにアクセスできるようにします。
    これはClusterIPのスーパーセットです。

LoadBalancer 
  - 現在のクラウドに外部ロードバランサを作成し(サポートされている場合)、
    Serciceに固定の外部IPを割り当てます。
    これはNodePortのスーパーセットです。

ExternalName 
  - 仕様のexternalNameで指定した名前のCNAMEレコードを返すことによって、
    任意の名前を使ってServiceを公開します。
    プロキシは使用されません。
    このタイプはv1.7以上のkube-dnsを必要とします。

さまざまな種類のServiceに関する詳細情報はUsing Source IP tutorialにあります。
アプリケーションとServiceの接続も参照してください。

加えて、
Serviceには、仕様にselectorを定義しないというユースケースがいくつかあります。
selectorを指定せずに作成したServiceについて、
対応するEndpointsオブジェクトは作成されません。
これによって、
ユーザーは手動でServiceを特定のエンドポイントにマッピングできます。
セレクタがない可能性があるもう1つの可能性は、
type：ExternalNameを厳密に使用していることです。

Kubernetes Serviceは、
Podの論理セットを定義し、
それらのPodに対する外部トラフィックの公開、
負荷分散、
およびサービス検出を可能にする抽象化層です。

## Serviceとラベル

Serviceは、
一連のPodにトラフィックをルーティングします。
Serviceは、アプリケーションに影響を与えることなく、
KubernetesでPodが死んだり複製したりすることを可能にする抽象概念です。
(アプリケーションのフロントエンドおよび
バックエンドコンポーネントなどの)依存Pod間の検出とルーティングは、
Kubernetes Serviceによって処理されます。

Serviceは、ラベルとセレクタを使用して一連のPodを照合します。
これは、
Kubernetes内のオブジェクトに対する論理操作を可能にするグループ化の
プリミティブです。
ラベルはオブジェクトに付けられたkey/valueのペアであり、
さまざまな方法で使用できます。

開発、テスト、および本番用のオブジェクトを指定する

バージョンタグを埋め込む

タグを使用してオブジェクトを分類する

ラベルは、
作成時またはそれ以降にオブジェクトにアタッチでき、
いつでも変更可能です。
Serviceを使用してアプリケーションを公開し、
いくつかのラベルを適用してみましょう。

# アプリケーションの複数インスタンスを実行

## アプリケーションのスケーリング

前回のモジュールでは、
Deploymentを作成し、それをService経由で公開しました。
該当のDeploymentでは、
アプリケーションを実行するためのPodを1つだけ作成しました。
トラフィックが増加した場合、
ユーザーの需要に対応するためにアプリケーションをスケールする必要があります。

スケーリングは、
Deploymentのレプリカの数を変更することによって実現可能です。

kubectl runコマンドの
--replicasパラメーターを使用することで、
最初から複数のインスタンスを含むDeploymentを作成できます。

# スケーリングの概要

Deploymentをスケールアウトすると、
新しいPodが作成され、
使用可能なリソースを持つNodeにスケジュールされます。
スケールすると、
Podの数が増えて新たな望ましい状態になります。
KubernetesはPodのオートスケーリングもサポートしていますが、
このチュートリアルでは範囲外です。
スケーリングを0に設定することも可能で、
指定された配置のすべてのPodを終了させます。

アプリケーションの複数インスタンスを実行するには、
それらすべてにトラフィックを分散する方法が必要になります。
Serviceには、公開されたDeploymentのすべてのPodに
ネットワークトラフィックを分散する統合ロードバランサがあります。
Serviceは、エンドポイントを使用して実行中のPodを継続的に監視し、
トラフィックが使用可能なPodにのみ送信されるようにします。

アプリケーションの複数のインスタンスを実行すると、
ダウンタイムなしでローリングアップデートを実行できます。
それについては、
次のモジュールで学習します。
それでは、オンラインのターミナルを使って、
アプリケーションをデプロイしてみましょう。

スケーリングは、
Deploymentのレプリカの数を変更することによって実現可能です。

# ローリングアップデートの実行

## アプリケーションのアップデート

ユーザーはアプリケーションが常に利用可能であることを期待し、
開発者はそれらの新しいバージョンを
1日に数回デプロイすることが期待されます。
Kubernetesでは、アプリケーションのアップデートをローリングアップデートで
行います。
ローリングアップデートでは、
Podインスタンスを新しいインスタンスで段階的にアップデートすることで、
ダウンタイムなしでDeploymentをアップデートできます。
新しいPodは、利用可能なリソースを持つNodeにスケジュールされます。

前回のモジュールでは、
複数のインスタンスを実行するようにアプリケーションをデプロイしました。

これは、
アプリケーションの可用性に影響を与えずにアップデートを行うための要件です。
デフォルトでは、
アップデート中に使用できなくなる可能性があるPodの最大数と作成できる新しいPodの最大数は1です。
どちらのオプションも、
Podの数または
全体数に対する割合(%)のいずれかに設定できます。
Kubernetesでは、アップデートはバージョン管理されており、
Deploymentにおけるアップデートは
以前の(stable)バージョンに戻すことができます。

デフォルトでは、アップロード中に使用できなくなる可能性があるPodの最大数と
作成できる新しいPodの最大数は１です。


アプリケーションのスケーリングと同様に、
Deploymentがパブリックに公開されている場合、
Serviceはアップデート中に利用可能なPodのみにトラフィックを負荷分散します。
利用可能なPodは、アプリケーションのユーザーが利用できるインスタンスです。

ローリングアップデートでは、次の操作が可能です。

コンテナイメージのアップデートを介した、
ある環境から別の環境へのアプリケーションの昇格

以前のバージョンへのロールバック

ダウンタイムなしでのアプリケーションのCI/CD
Deploymentがパブリックに公開されている場合、
Serviceはアップデート中に
利用可能なPodにのみトラフィックを負荷分散します。

次の対話型チュートリアルでは、
アプリケーションを新しいバージョンにアップデートし、
ロールバックも実行します。

***

１つのPodに含まれるコンテナ群はひとまとめで扱われ、
それを構成するコンテナ群は、同一のノード上にデプロイされ、ネットワークスタックや
ストレージを共有する

podがデプロイの最小単位

ConfigMapもSecretも任意の情報をキー・バリューペアとして定義したものです。
コンテナからこの情報を利用するためには、次の方法があります。

・ファイルとしてコンテナ内のファイルシステムにマウントする。
・コンテナ内の環境変数として見せる
